(window.webpackJsonp=window.webpackJsonp||[]).push([[422],{1777:function(t,e,s){"use strict";s.r(e);var r=s(5),_=Object(r.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"bucket、metric-核心概念"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#bucket、metric-核心概念"}},[t._v("#")]),t._v(" bucket、metric 核心概念")]),t._v(" "),e("p"),e("div",{staticClass:"table-of-contents"},[e("ul",[e("li",[e("a",{attrs:{href:"#bucket-桶"}},[t._v("bucket（桶）")])]),e("li",[e("a",{attrs:{href:"#metric"}},[t._v("metric")])])])]),e("p"),t._v(" "),e("h2",{attrs:{id:"bucket-桶"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#bucket-桶"}},[t._v("#")]),t._v(" bucket（桶）")]),t._v(" "),e("p",[t._v("表示一个数据分组，类似 mysql 中的 group")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("city")]),t._v(" "),e("th",[t._v("name")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("北京")]),t._v(" "),e("td",[t._v("小李")])]),t._v(" "),e("tr",[e("td",[t._v("北京")]),t._v(" "),e("td",[t._v("小王")])]),t._v(" "),e("tr",[e("td",[t._v("上海")]),t._v(" "),e("td",[t._v("小张")])]),t._v(" "),e("tr",[e("td",[t._v("上海")]),t._v(" "),e("td",[t._v("小丽")])]),t._v(" "),e("tr",[e("td",[t._v("上海")]),t._v(" "),e("td",[t._v("小陈")])])])]),t._v(" "),e("p",[t._v("基于如上数据，按 city 划分 buckets，划分出来两个bucket：")]),t._v(" "),e("ul",[e("li",[t._v("北京 bucket：包含了 2 个人，小李，小王")]),t._v(" "),e("li",[t._v("上海 bucket：包含了 3 个人，小张，小丽，小陈")])]),t._v(" "),e("p",[t._v("按照某个字段进行 bucket 划分，那个字段的值相同的那些数据，就会被划分到一个 bucket 中")]),t._v(" "),e("h2",{attrs:{id:"metric"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#metric"}},[t._v("#")]),t._v(" metric")]),t._v(" "),e("p",[t._v("表示对一个数据分组执行的统计操作")]),t._v(" "),e("p",[t._v("当我们有了一堆 bucket 之后，就可以对每个 bucket 中的数据进行聚合分词了，")]),t._v(" "),e("p",[t._v("metric 就是对一个 bucket 执行的某种聚合分析的操作，比如说求平均值、求最大值、求最小值")]),t._v(" "),e("p",[t._v("使用如下 sql 来理解这两个概念")]),t._v(" "),e("div",{staticClass:"language-sql line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" access_log "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" user_id\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br")])]),e("ul",[e("li",[t._v("bucket："),e("code",[t._v("group by user_id")]),t._v("，那些 user_id 相同的数据，就会被划分到一个 bucket 中")]),t._v(" "),e("li",[t._v("metric："),e("code",[t._v("count(*)")]),t._v("，对每个 user_id bucket 中所有的数据，计算一个数量")])])])}),[],!1,null,null,null);e.default=_.exports}}]);